---
title: "Bayesian modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages


```{r load-packages, message = FALSE}

library(ggplot2)      # library to create plots
library(dplyr)        # data manipulation
library(tidyr)
library(statsr)       # statistics functions
library(BAS)          # Bayesian statistics functions
library(GGally)       # library to create plots
library(knitr)        # required to apply knitr options 
library(grid)         # arrange plots 
library(gridExtra)    # arrange plots
library(MASS)         # AIC functions
library(pander)       # Prints an R object in Pandoc's markdown

```

### Load data


```{r load-data}
load("movies.Rdata")
```



* * *

## Part 1: Data

This dataset is a random sample of movies that includes information from two popular movie database and rating sites Rotten Tomatoes and IMDB. 

Generalizability:

We do not have information regarding the sampling method used. For this exercise, we assume it is a valid random sample that was generated using a random sampling method. In addition, IMDB movies database contains almost 10,000 movies. Our dataset contains 651 movies which is less than 10%.

Causality:

This is an observational study. There is no indication that random assignment has been performed in drawing this sample. Therefore, we cannot draw/infer conclusions on causality. At most, we can generalize on our findings.

Bias and reservations:

Considering many successful movies tend to generate sequels, we acknowledge potential bias on sequels rating from original movie rating. This requires taking into account temporal data that it is out of scope for this research topic.

In addition, audience score variable relies on voluntarily scoring from viewers. The viewers can be biased by rating movie based on their personal views and values reported to the movies genre and/or plot.

For the project at hand, I assume the observations in the sample dataset are independent. However, some variables in the dataset could be dependent of each other. I will analyse the variable collinearity and associations to identify such potential dependencies and remove them from the model.

* * *

## Part 2: Data manipulation

My research question is to analyse if to develop a Bayesian regression model to predict audience_score based on variables included in the dataset.

Such analysis could potentially aid movie theaters what movies to show and promote, and assign viewing rooms ahead of the movie release.

To that end, I will create new variables to aid with the model quality and accuracy.
.	Create new categorical (yes, no) variable 'feature_film' based on `title_type` to display feature films
.	Create new variable based on 'genre' called `drama` with levels yes (movies that are dramas) and no
.	Create new variable based on mpaa_rating called mpaa_rating_R with levels yes (movies that are R rated) and no
.	Create two new variables based on thtr_rel_month  called oscar_season with levels yes (if movie is released in November, October, or December) and new variable called summer_season with levels yes (if movie is released in May, June, July, or August) and no.


```{r}
my.movies <- movies %>% mutate(
  feature_film = as.factor(ifelse(title_type == 'Feature Film', 'yes', 'no')),
  drama = as.factor(ifelse(genre ==  'Drama', 'yes', 'no')),
  mpaa_rating_R = as.factor(ifelse(mpaa_rating == 'R', 'yes', 'no')),
  oscar_season = as.factor(ifelse(thtr_rel_month %in% c('10', '11', '12'), 'yes', 'no')),
  summer_season = as.factor(ifelse(thtr_rel_month %in% c('5','6', '7', '8'), 'yes', 'no')))



```

* * *

## Part 3: Exploratory data analysis

I will be looking to fit a Bayesian regression model to predict `audience_score`. The exploratory data analysis phase will address the relationships between the target variable and the newly created features.  


**New variable: `feature_film`**

```{r feature_film}

# Summary statistics of n, mean, and variance by factor group
my.table <- my.movies %>% 
            tbl_df %>%
            group_by(feature_film) %>%  
            summarize(n = n(), Mean = round(mean(audience_score),1), 
                      Variance = round(var(audience_score), 1))
pandoc.table(my.table)

# Plots
my.plot <- ggplot(data = my.movies, aes(x = feature_film, y = audience_score, fill = factor(feature_film), color = factor(feature_film))) +
  geom_boxplot(alpha =0.6) + 
    theme(legend.position=c(0.5, 0.2), plot.title = element_text(hjust = 0.5)) +
    labs(title = "Audience score vs Feature", y = "Audience Score", x = "Feature", fill = "feature_film",color = "feature_film")

my.density <- ggplot(my.movies, aes(audience_score)) + geom_density(aes(fill = factor(feature_film),color =factor(feature_film)), alpha = 0.6) +
  geom_vline(xintercept = my.table[[1,3]], color = "#F8766D") +
  geom_vline(xintercept = my.table[[1,3]] + sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[1,3]] - sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]] , color = "#00BFC4") +
  geom_vline(xintercept = my.table[[2,3]]  + sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]]  - sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  theme(legend.position=c(0.2, 0.8), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density chart", y = "P(Audience Score)", x = "Audience Score", fill = "feature_film",color = "feature_film")

grid.arrange(my.plot, my.density,ncol = 2)



```


Most of the movies in the dataset are feature films. Non-feature movies have a higher median audience score. Looking at variance and interquartile range `audience_score` and `feature_film` do not seem related. From the plots, we notice some overlap for both interquartile range and variance between the two variables. Further, at the end of this section I will conduct inferential Bayesian hypothesis testing, credible intervals and Bayesian factors for each feature. The purpose is to see the influence of the new features created on the `audience_score`.


**New variable: `drama`**

```{r drama}

# Summary statistics of n, mean, and variance by factor group
my.table <- my.movies %>% 
            tbl_df %>%
            group_by(drama) %>%  
            summarize(n = n(), Mean = round(mean(audience_score),1), 
                      Variance = round(var(audience_score), 1))
pandoc.table(my.table)

# Plots
my.plot <- ggplot(data = my.movies, aes(x = drama, y = audience_score, fill = factor(drama), color = factor(drama))) +
  geom_boxplot(alpha =0.6) + 
    theme(legend.position=c(0.5, 0.2), plot.title = element_text(hjust = 0.5)) +
    labs(title = "Audience score vs Drama", y = "Audience Score", x = "Drama", fill = "drama",color = "drama")

my.density <- ggplot(my.movies, aes(audience_score)) + geom_density(aes(fill = factor(drama),color =factor(drama)), alpha = 0.6) +
  geom_vline(xintercept = my.table[[1,3]], color = "#F8766D") +
  geom_vline(xintercept = my.table[[1,3]] + sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[1,3]] - sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]] , color = "#00BFC4") +
  geom_vline(xintercept = my.table[[2,3]]  + sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]]  - sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  theme(legend.position=c(0.2, 0.8), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density chart", y = "P(Audience Score)", x = "Audience Score", fill = "drama",color = "drama")

grid.arrange(my.plot, my.density,ncol = 2)

```

The movies are approximately 50% composed of drama genre. There is no apparent relationship between `drama` and `audience_score`.Furthermore, the chart indicates a large overlap in both interquartile range and probability densities. Further, at the end of this section I will conduct inferential Bayesian hypothesis testing, credible intervals and Bayesian factors for each feature. The purpose is to see the influence of the new features created on the `audience_score`.



**New variable: `mpaa_rating_R`**

```{r mpaa_rating_R}

# Summary statistics of n, mean, and variance by factor group
my.table <- my.movies %>% 
            tbl_df %>%
            group_by(mpaa_rating_R) %>%  
            summarize(n = n(), Mean = round(mean(audience_score),1), 
                      Variance = round(var(audience_score), 1))
pandoc.table(my.table)

# Plots
my.plot <- ggplot(data = my.movies, aes(x = mpaa_rating_R, y = audience_score, fill = factor(mpaa_rating_R), color = factor(mpaa_rating_R))) +
  geom_boxplot(alpha =0.6) + 
    theme(legend.position=c(0.5, 0.2), plot.title = element_text(hjust = 0.5)) +
    labs(title = "Audience score vs MPAA", y = "Audience Score", x = "MPAA Rating", fill = "mpaa_rating_R",color = "mpaa_rating_R")

my.density <- ggplot(my.movies, aes(audience_score)) + geom_density(aes(fill = factor(mpaa_rating_R),color =factor(mpaa_rating_R)), alpha = 0.6) +
  geom_vline(xintercept = my.table[[1,3]], color = "#F8766D") +
  geom_vline(xintercept = my.table[[1,3]] + sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[1,3]] - sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]] , color = "#00BFC4") +
  geom_vline(xintercept = my.table[[2,3]]  + sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]]  - sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  theme(legend.position=c(0.2, 0.8), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density chart", y = "P(Audience Score)", x = "Audience Score", fill = "mpaa_rating_R",color = "mpaa_rating_R")

grid.arrange(my.plot, my.density,ncol = 2)

```

Circa 50% of the movies are rated "R". The two variables do not seem to be related. The charts show a great overlap between IRQ and probability density of the groups.  Further, at the end of this section I will conduct inferential Bayesian hypothesis testing, credible intervals and Bayesian factors for each feature. The purpose is to see the influence of the new features created on the `audience_score`.




**New variable: `oscar_season`**

```{r oscar_season}

# Summary statistics of n, mean, and variance by factor group
my.table <- my.movies %>% 
            tbl_df %>%
            group_by(oscar_season) %>%  
            summarize(n = n(), Mean = round(mean(audience_score),1), 
                      Variance = round(var(audience_score), 1))
pandoc.table(my.table)

# Plots
my.plot <- ggplot(data = my.movies, aes(x = oscar_season, y = audience_score, fill = factor(oscar_season), color = factor(oscar_season))) +
  geom_boxplot(alpha =0.6) + 
    theme(legend.position=c(0.5, 0.2), plot.title = element_text(hjust = 0.5)) +
    labs(title = "Audience score vs Oscar Season", y = "Audience Score", x = "Oscar Season", fill = "oscar_season",color = "oscar_season")

my.density <- ggplot(my.movies, aes(audience_score)) + geom_density(aes(fill = factor(summer_season),color =factor(summer_season)), alpha = 0.6) +
  geom_vline(xintercept = my.table[[1,3]], color = "#F8766D") +
  geom_vline(xintercept = my.table[[1,3]] + sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[1,3]] - sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]] , color = "#00BFC4") +
  geom_vline(xintercept = my.table[[2,3]]  + sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]]  - sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  theme(legend.position=c(0.2, 0.8), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density chart", y = "P(Audience Score)", x = "Audience Score", fill = "oscar_season",color = "oscar_season")

grid.arrange(my.plot, my.density,ncol = 2)

```


There are double the movies released outside the Oscar season (October, November, December) than within. The median for Oscar season movies is slightly higher than outside the interval. There is no apparent relationship between `oscar_season` and `audience_score`. In addition, the charts indicate a big overlap in both IRQ and probability density of the two variables. At the end of this section I will conduct inferential Bayesian hypothesis testing, credible intervals and Bayesian factors for each feature. The purpose is to see the influence of the new features created on the `audience_score`.



**New variable: `summer_season`**

```{r summer_season}

# Summary statistics of n, mean, and variance by factor group
my.table <- my.movies %>% 
            tbl_df %>%
            group_by(summer_season) %>%  
            summarize(n = n(), Mean = round(mean(audience_score),1), 
                      Variance = round(var(audience_score), 1))
pandoc.table(my.table)

# Plots
my.plot <- ggplot(data = my.movies, aes(x = summer_season, y = audience_score, fill = factor(summer_season), color = factor(summer_season))) +
  geom_boxplot(alpha =0.6) + 
    theme(legend.position=c(0.5, 0.2), plot.title = element_text(hjust = 0.5)) +
    labs(title = "Audience score vs Summer Season", y = "Audience Score", x = "Summer Season", fill = "summer_season",color = "summer_season")

my.density <- ggplot(my.movies, aes(audience_score)) + geom_density(aes(fill = factor(summer_season),color =factor(summer_season)), alpha = 0.6) +
  geom_vline(xintercept = my.table[[1,3]], color = "#F8766D") +
  geom_vline(xintercept = my.table[[1,3]] + sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[1,3]] - sqrt(my.table[[1,4]]), color = "#F8766D", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]] , color = "#00BFC4") +
  geom_vline(xintercept = my.table[[2,3]]  + sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  geom_vline(xintercept = my.table[[2,3]]  - sqrt(my.table[[2,4]]), color = "#00BFC4", lty = 2, alpha =0.6) +
  theme(legend.position=c(0.2, 0.8), plot.title = element_text(hjust = 0.5)) +
  labs(title = "Density chart", y = "P(Audience Score)", x = "Audience Score", fill = "summer_season",color = "summer_season")

grid.arrange(my.plot, my.density,ncol = 2)

```


Twice as many movies are released outside the summer months than in the summer. We defined summer season the months of May, June, July, and August. There is no apparent relationship between the two groups. In addition, the charts indicate a big overlap in both IRQ and probability density of the two variables. 



Next step I will conduct the Bayesian hypothesis testing on the audience score of all movies in the dataset using the bayes_inference function. I assume the status quo, the new features will not influence the `audience_score`.

Using the `bayes_inference()` function in R to describe the relationship between observed data *y* and all relevant influencing parameters. Calculate the credible intervals, Baysian factors, prior and posterior distributions.


```{r HT}

bayes_inference(y = audience_score, data = my.movies, cred_level = 0.95,
                statistic = "mean", type = "ci", null = 0, show_res = TRUE, 
                show_summ = TRUE)

bayes_inference(x = feature_film, y = audience_score, data = my.movies, cred_level = 0.95,
                hypothesis_prior = c(0.5, 0.5),statistic = "mean", type = "ht", null = 0,
                alternative = 'twosided', show_res = TRUE, show_summ = TRUE)

bayes_inference(x = oscar_season, y = audience_score, data = my.movies, cred_level = 0.95,
                hypothesis_prior = c(0.5, 0.5), statistic = "mean", type = "ht", null = 0,
                alternative = 'twosided', show_res = TRUE, show_summ = TRUE)
bayes_inference(x = summer_season, y = audience_score, data = my.movies, cred_level = 0.95,
                hypothesis_prior = c(0.5, 0.5), statistic = "mean", type = "ht", null = 0,
                alternative = 'twosided', show_res = TRUE, show_summ = TRUE)
bayes_inference(x = drama, y = audience_score, data = my.movies, cred_level = 0.95,
                hypothesis_prior = c(0.5, 0.5), statistic = "mean", type = "ht", null = 0,
                alternative = 'twosided', show_res = TRUE, show_summ = TRUE)
bayes_inference(x = mpaa_rating_R, y = audience_score, data = my.movies, cred_level = 0.95,
                hypothesis_prior = c(0.5, 0.5), statistic = "mean", type = "ht", null = 0,
                alternative = 'twosided', show_res = TRUE, show_summ = TRUE)


```
 

Interpretation of Bayes factors results:

```{r Baysian_inference, echo=FALSE}

col.names <- c("Feature", "BF[H1:H2]", 	"BF[H2:H1]" ,	"Evidence against")
c1 <- c('feature_film',' ','4.221452e+13','H1 (Very Strong)')
c2 <- c('oscar_season','13.3993','','H2 (Positive)')
c3 <- c('summer_season','21.7118',' ','H2 (Positive)')
c4 <- c('drama',' ','22.6567','H1 (Positive)')
c5 <- c('mpaa_rating_R','23.9679',' ','H2 (Positive)')

my.results <- rbind(c1,c2,c3,c4,c5)

df<-data.frame(my.results)
colnames(df) <- col.names

kable(df,row.names = F)

```

For the `feature_film` feature there is strong evidence against H1, therefore there is a significant difference between `audience_score` and `feature_film`. The data indicates that the other features we created show positive evidence but there is no significant difference for `audience_scores` and all the other (new) features (`drama`,`mpaa_rating_R`, `oscar_season`, `summer_season`). 

* * *



## Part 4: Modeling

Next, I will develop a Bayesian regression model to predict audience_score from the following explanatory variables(`feature_film`,	`drama`,	`runtime`,	`mpaa_rating_R`,	`thtr_rel_year`,	`oscar_season`,	`summer_season`,	`imdb_rating`,	`imdb_num_votes`,	`critics_score`,	`best_pic_nom`,	`best_pic_win`,	`best_actor_win`,	`best_actress_win`,	`best_dir_win`,	`top200_box`)
Please, note that some of these variables are in the original dataset provided, and others are new variables I constructed earlier:

First I will create a subset movies dataset with the variables used in the model then use the BAS package to fit the Bayesian regression model to `my.movies` dataset. Also remove one row due to missing data.

```{r subset for modell}
#subset the data 
my.movies <- my.movies %>% dplyr::select(audience_score, feature_film, drama, runtime, mpaa_rating_R, thtr_rel_year, oscar_season, summer_season,imdb_rating, imdb_num_votes, critics_score, best_pic_nom, best_pic_win, best_actor_win, best_actress_win, best_dir_win, top200_box)
my.movies <- na.exclude(my.movies)

```


*Bayesian Information Criterion(BIC)*

A BIC prior and uniform model prior is used.



```{r Bayesian Information Criterion(BIC) }

my.movies.BIC <-  bas.lm(audience_score ~ ., 
                         prior = "BIC",
                         modelprior = uniform(), 
                         data = my.movies)

```

*Coefficients Overview*

Calculate the coefficients for each feature: marginal posterior mean, standard deviation and posterior inclusion probabilities obtained by BMA.

```{r Coefficients Overview}

my.coef <- coef(my.movies.BIC, estimator = "BMA")

# find posterior probabilities 
coefs_bma <- data.frame(parameter = my.coef$namesx, post_mean = my.coef$postmean, post_SD = my.coef$postsd, post_pne0 = my.coef$probne0) %>% arrange(desc(post_pne0)) %>% filter(parameter != "Intercept")

coefs_bma$parameter <- factor(coefs_bma$parameter, levels = coefs_bma$parameter[order(coefs_bma$post_pne0, decreasing = TRUE)])
high_pne0 <- data.frame(parameter = coefs_bma$parameter, post_pne0 = coefs_bma$post_pne0) %>% filter(post_pne0 > 0.5)
# Plot the Data
ggplot(coefs_bma, aes(x = parameter, y = post_pne0)) + 
    geom_pointrange(aes(ymax = post_pne0), ymin = 0) +
    geom_pointrange(data=high_pne0, aes(x = parameter, y = post_pne0, ymax = post_pne0), ymin = 0, color = "red") +
    geom_hline(yintercept = 0.5, color = "red") +
    labs(title = "Posterior Marginal Inclusion Probabilities of Predictor Variables",x="Predictors",y = "Marginal Inclusion Probability") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1), plot.title = element_text(hjust = 0.5))


```

Bayesian Model Average (BMA) is used because it provides  for the greatest uncertainty in model construction by including all the probabilities for every possible model. We can easily notice in the chart above that only `idbm_rating` and `critics_score` have an inclusion probability higher than 0.5 as highlighted in red.

Next we plot the credible intervals for betas

```{r}
# find credible intervals for betas
coefs_beta <- data.frame(confint(my.coef, c(2:17))[,])
coefs_beta$parameter <- rownames(coefs_beta)
rownames(coefs_beta) <- NULL
coefs_bma <- coefs_bma %>% left_join(coefs_beta)
coefs_bma$parameter <- factor(coefs_bma$parameter, levels = coefs_bma$parameter[order(coefs_bma$beta)])
high_pne0 <- high_pne0 %>% left_join(coefs_bma)


# Plot the data
ggplot(coefs_bma, aes(y = beta, x = parameter)) + 
    geom_pointrange(aes(ymax = X97.5., ymin =X2.5.)) +
    geom_point(data=high_pne0, aes(y = beta, x = parameter), color = "red", size = 2.5) +
    geom_hline(yintercept = 0, color = "red") +
    labs(title = "95% Credible Intervals for Betas",x="Predictors",y = "Beta") +
    theme(plot.title = element_text(hjust = 0.5)) +
    coord_flip() 

```


The plot shows that in addition to a high marginal inclusion probability (>0.5) `imdb_rating` has a big beta(the red dots). We can also notice that every point in `imdb_rating` increases `audience_score` by 15 points! 

*Summary of Top Models*

Using the summary function on the model `my.movies.BIC` we get the top five models and values rounded to 3 decimal point for better visual clarity. The function produces '2^16' models but displays the top 5.


```{r model summary}
round(summary(my.movies.BIC), 3)


```

The models in the table are ordered from best to worst using their posterior probabilities. The `model 1` shows the best performance and contains the `intercept`, `runtime`, `mdb_rating`, and `critics_score` variables indicated by the non zero values. The top two models (`model 1` and `model 2`) add up to 26% of probability with the remaining 74% distributed among the other 14 remaining models.


*Model Diagnostics*

I will use the image function to visualize the model uncertainty.

```{r Model Uncertainty}

image(my.movies.BIC, rotate = F)


```


By default, the top 20 models are displayed with the best model on the left side, indicted by number 1. The image shows that the best model is produced using `runtime`, `imdb_rating`, and `critics_score` features.



In this step, the residuals are evaluated from a model bias and variance perspective under Bayesian Model Averaging (BMA). 

```{r Model Diagnostics: }

plot(my.movies.BIC, ask=F, which=1)
plot(my.movies.BIC, ask=F, which=2)
plot(my.movies.BIC, ask=F, which=3)
plot(my.movies.BIC, ask=F, which=4)

```
 
In the first plot, the 'Residuals vs Fitted' values show that most of the residuals are centred at zero. The residuals variance decreases at higher predicted values (60+). For values below 40, the model underestimates the audience scores and the bias gets worse at lower predicted values. In addition, the plot points out three possible outliers, the labelled points.

The second plot shows the cumulative model probability, adding up the model probabilities each time a new model is sampled. We notice stops increasing because each additional model only adds a small incremental increase to cumulative probability.

Next is the plot of model size versus the log of the marginal likelihood, our Bayes factor to compare each model to the null model. By model dimension, we mean the number of regression coefficients including the intercept for each model versus the log of the marginal likelihood of the model.

Last, we have a plot showing the importance of different predictors. The lines in red correspond to the variables where the marginal posterior inclusion probability, or PIP, is greater than 0.5 suggesting that these variables are important for predicting the `audience_score`. While the variables in black have a posterior inclusion probabilities less than 0.5. These small PIPs can arise when two or more variables are highly correlated, similar to large p-values with multicollinearity. Therefore, caution should be used in using the PIPs to eliminate variables.



Just as in the course material, in order to simplify and arrive at the best model we'll use a new conjugate prior distribution called Zellner's g prior and MCMC model sampling and repeat the model diagnostics plots steps performed for BIC.


```{r Zellner-MCMC }

my.movies.ZS <-  bas.lm(audience_score ~ .,
                        prior = "ZS-null",
                        modelprior = uniform(),
                        method = "MCMC",
                        data = my.movies)


image(my.movies.ZS, rotate = F)

plot(my.movies.ZS, ask=F, which=1)
plot(my.movies.ZS, ask=F, which=2)
plot(my.movies.ZS, ask=F, which=3)
plot(my.movies.ZS, ask=F, which=4)

```


The model based on the different priors (ZS-null and MCMC) advices different predictors. With the BIC prior, we get an ideal model with the features `runtime`, `imdb_rating`, and `critics_score`, while the ZS-null prior proposes a model with features `imdb_rating` and `critics_score`.


Using the same reasoning as with the BIC prior model, the first image shows the best model to the left (number one)  with the features `imdb_rating` and `critics_score`. 

The model demonstrate a decline in residual variance at higher predicted values. For fitted values less than 40, the model underestimates the audience scores. This bias gets gradually worse the lower the predicted value. Similar as with BIC prior, the plot labels three possible outliers.

The second plot shows the cumulative model probabilities, adding up the model probabilities each time a new model is sampled. We can see that we discovered about 6,000 unique models with MCMC sampling.  The probability is starting to level off, indicating that these additional models are not adding much more additional probability. These probabilities are proportional to the marginal likelihoods times priors, rather than Monte Carlo frequencies.

Next is the plot of model size versus the log of the marginal likelihood, our Bayes factor to compare each model to the null model. We can see that the models with the highest Bayes factors or marginal likelihoods have around two or three predictors. The null model has a log marginal of 0, or a Bayes factor of 1.

Finally, in the last plot the lines in red correspond to the variables where the marginal posterior inclusion probability is greater than 0.5 which denotes the features as important for predicting the `audience_score`.


*Final Model*

Based on the previous analysis I will use the following model to continue with the prediction: audience_score ~ imdb_rating + critics_score. We define 2*10^6 iterations for the model

```{r Final Model}

# Create a new dataset 
final.movies <- my.movies %>% dplyr::select(audience_score, imdb_rating,critics_score )


final.movies.ZS =  bas.lm(audience_score ~ .,  
                      data = final.movies,
                      prior = "ZS-null",
                      modelprior = uniform(),
                      method = "MCMC", 
                      MCMC.iterations =2*10^6) 

```




* * *

## Part 5: Prediction

Finally, for this part, I pick a movie from 2016 (a new movie that is not in the sample) and do a prediction for this movie using the model I developed and the predict function in R.

I select Hidden Figures that is dear to me being fun, educational, and entertaining.

Movie reference [Hidden Figures(IMDB)](http://www.imdb.com/title/tt4846340/?ref_=adv_li_tt)
Movie reference [Hidden Figures(RT)](https://www.rottentomatoes.com/m/hidden_figures/)


```{r Prediction}

pred_movie = data.frame(audience_score = 93, imdb_rating = 7.8, critics_score=93)


my.prediction <- predict(final.movies.ZS, newdata = pred_movie, estimator = "BMA", se.fit=TRUE)

ci_pred_movie  <- confint(my.prediction, parm="pred")


pred.final_score<- data.frame(type="95% Credible Interval", lwr = ci_pred_movie[1], pred = ci_pred_movie[3], upr = ci_pred_movie[2]) 




pandoc.table(pred.final_score)



```


The predicted audience score for the movie Hidden Figures is 84 and the credible interval is 63 for the lower limit and 104 for the higher limit. The actual value is 93 according to Rotten Tomatoes, which falls within the predicted credible interval.

* * *

## Part 6: Conclusion

I started with a dataset comprised of 651 randomly sampled movies produced and released before 2016. Some of these variables are only there for informational purposes and do not make any sense to include in a statistical analysis. During the modeling process, I created additional features that in the end were not used, because they are not significant predictors of audience score.


While we started with a BIC prior and uniform model prior and fitted a BMA regression model we ended up using the Zellner-Siow Cauchy prior with an MCMC method. 

The proposed linear model shows a good prediction accuracy, however the model is based on a very small sample. It can prove advantageous more data and do more feature engineering. 

More factors that underscore the movie plot, and marketing spend, ratings on trailers released, and possible social media 'hype' are also possible new features.

Last but not the least we should also gather information regarding sequels for movies that do qualify as this can inject bias in the data and model.



**Thank you for your time!**


